# Base compose file with common settings
services:
  ollama:
    build: .
    container_name: ${OLLAMA_CONTAINER_NAME:-deepseek-ollama}
    env_file:
      - .env.w11-4090m
    environment:
      - MODEL_SIZE=${MODEL_SIZE}
    volumes:
      - ollama-models:/root/.ollama
    ports:
      - '${OLLAMA_PORT:-11434}:11434'

  webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ${WEBUI_CONTAINER_NAME:-deepseek-webui}
    ports:
      - '${WEBUI_PORT:-8080}:8080'
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - ENV=${ENVIRONMENT:-prod}
      - PORT=8080
      - SCARF_NO_ANALYTICS=${SCARF_NO_ANALYTICS:-true}
      - DO_NOT_TRACK=${DO_NOT_TRACK:-true}
      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-false}
    volumes:
      - webui-data:/app/backend/data
    depends_on:
      - ollama

volumes:
  ollama-models:
  webui-data:
